# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1owLADryi-aTps5jMuSWzUa-pUMjb8SrN
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense

df = pd.read_csv('/content/sample_data/kidney_disease.csv')
df.isnull().sum()

from sklearn.impute import SimpleImputer
imp_mode= SimpleImputer (missing_values=np.nan, strategy='most_frequent')
df_imputed=pd.DataFrame(imp_mode.fit_transform(df))
df_imputed.columns=df.columns

df_imputed.isnull().sum()

for i in df_imputed.columns:
  print("      *",i,"*     ")
  print()
  print(set(df_imputed[i].tolist()))
  print()


print(df_imputed ["rc"].mode()) 
print(df_imputed ["wc"].mode()) 
print(df_imputed ["pcv"].mode())

df_imputed ["classification"]=df_imputed ["classification"].apply(lambda x: 'ckd' if x=="ckd\t" else x)
df_imputed ["cad"]=df_imputed ["cad"].apply(lambda x: 'no' if x== "\tno" else x)


df_imputed ["dm"]=df_imputed ["dm"].apply(lambda x: 'no' if x== "\tno" else x)
df_imputed ["dm"]=df_imputed ["dm"].apply(lambda x: 'yes' if x=="\tyes" else x)
df_imputed ["dm"]=df_imputed ["dm"].apply(lambda x: 'yes' if x == ' yes' else x)

df_imputed ["rc"]=df_imputed ["rc"].apply(lambda x: '5.2' if x=='\t?' else x)

df_imputed ["wc"]=df_imputed ["wc"].apply(lambda x: '9800' if x=='\t6200' else x)
df_imputed ["wc"]=df_imputed ["wc"].apply(lambda x: '9800' if x== '\t8400' else x)
df_imputed ["wc"]=df_imputed ["wc"].apply(lambda x: '9800' if x== '\t?'else x)

df_imputed ["pcv"]=df_imputed ["pcv"].apply(lambda x: '41' if x=='\t43' else x)
df_imputed ["pcv"]=df_imputed ["pcv"].apply(lambda x:'41' if x== '\t?' else x)

for i in df_imputed.columns:
  print("      *",i,"*     ")
  print()
  print(set(df_imputed[i].tolist()))
  print()


df.dtypes
df_imputed.dtypes
for i in df.select_dtypes (exclude=["object"]).columns:
  df_imputed[i]=df_imputed[i].apply(lambda x: float(x))
df_imputed.dtypes

# Label encoding to convert categorical values to numerical 
from sklearn import preprocessing
df_enco=df_imputed.apply(preprocessing.LabelEncoder().fit_transform)
df_enco
X = df_enco.iloc[:,1:-1] 
y = df_enco.iloc[:,-1] 

scaller = StandardScaler()
X = scaller.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) 
y_train
from keras.utils import np_utils
y_train = np_utils.to_categorical(y_train)

model = Sequential()
model.add(Dense(6, input_dim=24, activation='relu'))
model.add(Dense(4, activation='relu'))
model.add(Dense(2, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# fit the keras model on the dataset
model.fit(X_train, y_train,  epochs=30, batch_size=5)

acc = model.evaluate(X_train, y_train)
print("Loss:", acc[0], " Accuracy:", acc[1])

pred = model.predict(X_test)
pred_y = pred.argmax(axis=-1)